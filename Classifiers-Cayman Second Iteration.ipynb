{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(filename, onehotencode=False, bool_bmi=True, categorical_col=[], onehotencode_column=[], drop_column = [], drop_value_num=5, drop_nan_percent=0.4):\n",
    "    \"\"\"Return the cleaned dataframe or one-hot encoded dataframe plus the label\n",
    "        Parameters:\n",
    "            filename (string): the name of the .csv file\n",
    "            onehotencode (boolean): if true, return one-hot encoded dataframe plus the label \n",
    "            bool_bmi (boolean): if true, change bmi to True/False\n",
    "            categorical_col (list): a list of categorical columns\n",
    "            onehotencode_column (list): a list of columns to one-hot encode if onehotencode is true\n",
    "            drop_column (list): a list of columns to drop\n",
    "            drop_value_num (int): the threshold for droping the value in a column\n",
    "            drop_nan_percent (float): the threshold for droping the nan (in percentage)\n",
    "        Returns:\n",
    "            df (DataFrame): cleaned dataFrame\n",
    "            or \n",
    "            df (DataFrame): cleaned one-hot encodedand dataFrame\n",
    "            label (Series): label for stroke\n",
    "    \"\"\"\n",
    "    # read in the file to clean\n",
    "    df = pd.read_csv(filename,index_col=0)\n",
    "    df = df.sample(frac=1)\n",
    "    N = len(df)\n",
    "    # get all the unique column\n",
    "    columns = df.columns\n",
    "    \n",
    "    \n",
    "    # check if there is duplicate\n",
    "    if len(df.duplicated()) != 0:\n",
    "        df = df.drop_duplicates(keep = 'last')\n",
    "        \n",
    "    # change\n",
    "    if bool_bmi:\n",
    "        df['bmi'] = df['bmi'].isna().astype(int)\n",
    "    else:\n",
    "        df = df.drop(\"bmi\", axis=1)\n",
    "    \n",
    "    # drop unwanted columns\n",
    "    df = df.drop(columns=drop_column)\n",
    "        \n",
    "    # loop through all the columns to drop unecessary \n",
    "    for col in categorical_col:\n",
    "        # check if it is object categorical feature\n",
    "        if df[col].dtypes == object:\n",
    "            # get unique values for the column\n",
    "            values = pd.unique(df[col])\n",
    "            # check the number of the values and drop if too few\n",
    "            for v in values:\n",
    "                if len(df[df[col] == v]) < drop_value_num:\n",
    "                    df = df.drop(df[df[col]== v].index)\n",
    "        # if it is numercial categorical feature\n",
    "        else:\n",
    "            # get unique values for the column\n",
    "            values = pd.unique(df[col])\n",
    "            # check the number of the values and drop if too few\n",
    "            for v in values:\n",
    "                if len(df[df[col] == v]) < drop_value_num:\n",
    "                    df = df.drop(df[df[col]== v].index)\n",
    "    # the nan is less than drop_nan_percent percent of the dataset, drop them\n",
    "    if sum(df.isna().sum()) < N*drop_nan_percent:\n",
    "        df = df.dropna()\n",
    "        \n",
    "    # one hot encode if true\n",
    "    if onehotencode:\n",
    "        df = pd.get_dummies(df, columns=onehotencode_column)\n",
    "        label = df['stroke']\n",
    "        df = df.drop('stroke', axis=1)\n",
    "        # return the one hot encode dataframe and label\n",
    "        return df, label\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'gender', 'age', 'hypertension', 'heart_disease', 'ever_married',\n",
      "       'work_type', 'Residence_type', 'avg_glucose_level', 'bmi',\n",
      "       'smoking_status', 'stroke'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data, target = data_cleaning(\"healthcare-dataset-stroke-data.csv\", onehotencode=True, categorical_col=['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status'], onehotencode_column=['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Gaussian/Bernoulli w/o SMOTE:\n",
      "Recall: 0.02631578947368421\n",
      "Accuracy: 0.9445531637312459\n",
      "Precision: 0.15384615384615385\n",
      "F1 Score: 0.0449438202247191\n",
      "\n",
      "Bernoulli (just categorical) w/o SMOTE:\n",
      "Recall: 0.07894736842105263\n",
      "Accuracy: 0.9360730593607306\n",
      "Precision: 0.17647058823529413\n",
      "F1 Score: 0.10909090909090909\n",
      "\n",
      "Gaussian (just continuous) w/o SMOTE:\n",
      "Recall: 0.14473684210526316\n",
      "Accuracy: 0.9256360078277887\n",
      "Precision: 0.18333333333333332\n",
      "F1 Score: 0.16176470588235292\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes w/o SMOTE\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3)\n",
    "\n",
    "bernoulliSet = X_train.drop(columns=[\"avg_glucose_level\", \"age\"])\n",
    "gaussianSet = X_train[[\"avg_glucose_level\", \"age\"]]\n",
    "\n",
    "bernoulliClassifier = BernoulliNB()\n",
    "gaussianClassifier = GaussianNB()\n",
    "\n",
    "bernoulliTest = X_test.drop(columns=[\"avg_glucose_level\", \"age\"])\n",
    "gaussianTest = X_test[[\"avg_glucose_level\", \"age\"]]\n",
    "\n",
    "bernoulliProb = bernoulliClassifier.fit(bernoulliSet, y_train).predict_proba(bernoulliTest)\n",
    "gaussianProb = gaussianClassifier.fit(gaussianSet, y_train).predict_proba(gaussianTest)\n",
    "prediction = (np.argmax(bernoulliProb*gaussianProb, axis = 1))\n",
    "\n",
    "print(\"Combined Gaussian/Bernoulli w/o SMOTE:\")\n",
    "print(\"Recall:\", recall_score(y_test, prediction))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, prediction))\n",
    "print(\"Precision:\", precision_score(y_test, prediction))\n",
    "print(\"F1 Score:\", f1_score(y_test, prediction))\n",
    "print()\n",
    "\n",
    "prediction = bernoulliClassifier.fit(bernoulliSet, y_train).predict(bernoulliTest)\n",
    "\n",
    "print(\"Bernoulli (just categorical) w/o SMOTE:\")\n",
    "print(\"Recall:\", recall_score(y_test, prediction))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, prediction))\n",
    "print(\"Precision:\", precision_score(y_test, prediction))\n",
    "print(\"F1 Score:\", f1_score(y_test, prediction))\n",
    "print()\n",
    "\n",
    "prediction = gaussianClassifier.fit(gaussianSet, y_train).predict(gaussianTest)\n",
    "\n",
    "print(\"Gaussian (just continuous) w/o SMOTE:\")\n",
    "print(\"Recall:\", recall_score(y_test, prediction))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, prediction))\n",
    "print(\"Precision:\", precision_score(y_test, prediction))\n",
    "print(\"F1 Score:\", f1_score(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Gaussian/Bernoulli w/ SMOTE:\n",
      "Recall: 0.5974025974025974\n",
      "Accuracy: 0.7638617090671885\n",
      "Precision: 0.1220159151193634\n",
      "F1 Score: 0.20264317180616742\n",
      "\n",
      "Bernoulli (just categorical) w/ SMOTE:\n",
      "Recall: 0.2597402597402597\n",
      "Accuracy: 0.8016960208741031\n",
      "Precision: 0.0749063670411985\n",
      "F1 Score: 0.11627906976744186\n",
      "\n",
      "Gaussian (just continuous) w/ SMOTE:\n",
      "Recall: 0.8181818181818182\n",
      "Accuracy: 0.6999347684279191\n",
      "Precision: 0.1237721021611002\n",
      "F1 Score: 0.21501706484641636\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes w/ SMOTE\n",
    "\n",
    "sm = SMOTE()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3)\n",
    "\n",
    "X_train, y_train = sm.fit_resample(X_train,y_train)\n",
    "\n",
    "bernoulliSet = X_train.drop(columns=[\"avg_glucose_level\", \"age\"])\n",
    "gaussianSet = X_train[[\"avg_glucose_level\", \"age\"]]\n",
    "\n",
    "bernoulliClassifier = BernoulliNB()\n",
    "gaussianClassifier = GaussianNB()\n",
    "\n",
    "bernoulliTest = X_test.drop(columns=[\"avg_glucose_level\", \"age\"])\n",
    "gaussianTest = X_test[[\"avg_glucose_level\", \"age\"]]\n",
    "\n",
    "bernoulliProb = bernoulliClassifier.fit(bernoulliSet, y_train).predict_proba(bernoulliTest)\n",
    "gaussianProb = gaussianClassifier.fit(gaussianSet, y_train).predict_proba(gaussianTest)\n",
    "prediction = (np.argmax(bernoulliProb*gaussianProb, axis = 1))\n",
    "\n",
    "#prediction = bernoulliClassifier.fit(bernoulliSet, y_train).predict(bernoulliTest)\n",
    "#prediction = gaussianClassifier.fit(gaussianSet, y_train).predict(gaussianTest)\n",
    "\n",
    "print(\"Combined Gaussian/Bernoulli w/ SMOTE:\")\n",
    "print(\"Recall:\", recall_score(y_test, prediction))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, prediction))\n",
    "print(\"Precision:\", precision_score(y_test, prediction))\n",
    "print(\"F1 Score:\", f1_score(y_test, prediction))\n",
    "print()\n",
    "\n",
    "prediction = bernoulliClassifier.fit(bernoulliSet, y_train).predict(bernoulliTest)\n",
    "\n",
    "print(\"Bernoulli (just categorical) w/ SMOTE:\")\n",
    "print(\"Recall:\", recall_score(y_test, prediction))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, prediction))\n",
    "print(\"Precision:\", precision_score(y_test, prediction))\n",
    "print(\"F1 Score:\", f1_score(y_test, prediction))\n",
    "print()\n",
    "\n",
    "prediction = gaussianClassifier.fit(gaussianSet, y_train).predict(gaussianTest)\n",
    "\n",
    "print(\"Gaussian (just continuous) w/ SMOTE:\")\n",
    "print(\"Recall:\", recall_score(y_test, prediction))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, prediction))\n",
    "print(\"Precision:\", precision_score(y_test, prediction))\n",
    "print(\"F1 Score:\", f1_score(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Gaussian/Bernoulli w/o SMOTE (Cross-Validated 7-Fold):\n",
      "Recall mean: 0.05136448742760537\n",
      "Accuracy mean: 0.9448025469841808\n",
      "F1 Score mean: 0.08252040616492118\n",
      "\n",
      "Bernoulli w/o SMOTE (Cross-Validated 7-Fold):\n",
      "Recall mean: 0.06917371638234517\n",
      "Accuracy mean: 0.9369731476783735\n",
      "F1 Score mean: 0.09562552430874734\n",
      "\n",
      "Gaussian w/o SMOTE (Cross-Validated 7-Fold):\n",
      "Recall mean: 0.1548348622552158\n",
      "Accuracy mean: 0.9222922857626054\n",
      "F1 Score mean: 0.16226184144629455\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes w/ SMOTE Cross Validated (7-Fold)\n",
    "\n",
    "kf = KFold(n_splits = 7)\n",
    "\n",
    "recallScoresCombined = []\n",
    "accuracyScoresCombined = []\n",
    "f1ScoresCombined = []\n",
    "\n",
    "recallScoresGaussian = []\n",
    "accuracyScoresGaussian = []\n",
    "f1ScoresGaussian = []\n",
    "\n",
    "recallScoresBernoulli = []\n",
    "accuracyScoresBernoulli = []\n",
    "f1ScoresBernoulli = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(data), 1):\n",
    "    X_train = data.iloc[train_index]\n",
    "    y_train = target.iloc[train_index]\n",
    "    X_test = data.iloc[test_index]\n",
    "    y_test = target.iloc[test_index]\n",
    "\n",
    "    X_train_oversampled, y_train_oversampled = X_train, y_train\n",
    "\n",
    "    bernoulliSet = X_train_oversampled.drop(columns=[\"avg_glucose_level\", \"age\"])\n",
    "    gaussianSet = X_train_oversampled[[\"avg_glucose_level\", \"age\"]]\n",
    "\n",
    "    bernoulliClassifier = BernoulliNB()\n",
    "    gaussianClassifier = GaussianNB()\n",
    "\n",
    "    bernoulliTest = X_test.drop(columns=[\"avg_glucose_level\", \"age\"])\n",
    "    gaussianTest = X_test[[\"avg_glucose_level\", \"age\"]]\n",
    "\n",
    "    bernoulliProb = bernoulliClassifier.fit(bernoulliSet, y_train_oversampled).predict_proba(bernoulliTest)\n",
    "    gaussianProb = gaussianClassifier.fit(gaussianSet, y_train_oversampled).predict_proba(gaussianTest)\n",
    "    prediction = (np.argmax(bernoulliProb*gaussianProb, axis = 1))\n",
    "\n",
    "    recallScoresCombined.append(recall_score(y_test, prediction))\n",
    "    accuracyScoresCombined.append(accuracy_score(y_test, prediction))\n",
    "    f1ScoresCombined.append(f1_score(y_test, prediction))\n",
    "\n",
    "    prediction = bernoulliClassifier.fit(bernoulliSet, y_train_oversampled).predict(bernoulliTest)\n",
    "    \n",
    "    recallScoresBernoulli.append(recall_score(y_test, prediction))\n",
    "    accuracyScoresBernoulli.append(accuracy_score(y_test, prediction))\n",
    "    f1ScoresBernoulli.append(f1_score(y_test, prediction))\n",
    "    \n",
    "    prediction = gaussianClassifier.fit(gaussianSet, y_train_oversampled).predict(gaussianTest)\n",
    "\n",
    "    recallScoresGaussian.append(recall_score(y_test, prediction))\n",
    "    accuracyScoresGaussian.append(accuracy_score(y_test, prediction))\n",
    "    f1ScoresGaussian.append(f1_score(y_test, prediction))\n",
    "\n",
    "print(\"Combined Gaussian/Bernoulli w/o SMOTE (Cross-Validated 7-Fold):\")\n",
    "print(\"Recall mean:\", np.mean(recallScoresCombined))\n",
    "print(\"Accuracy mean:\", np.mean(accuracyScoresCombined))\n",
    "print(\"F1 Score mean:\", np.mean(f1ScoresCombined))\n",
    "print()\n",
    "\n",
    "print(\"Bernoulli w/o SMOTE (Cross-Validated 7-Fold):\")\n",
    "print(\"Recall mean:\", np.mean(recallScoresBernoulli))\n",
    "print(\"Accuracy mean:\", np.mean(accuracyScoresBernoulli))\n",
    "print(\"F1 Score mean:\", np.mean(f1ScoresBernoulli))\n",
    "print()\n",
    "\n",
    "print(\"Gaussian w/o SMOTE (Cross-Validated 7-Fold):\")\n",
    "print(\"Recall mean:\", np.mean(recallScoresGaussian))\n",
    "print(\"Accuracy mean:\", np.mean(accuracyScoresGaussian))\n",
    "print(\"F1 Score mean:\", np.mean(f1ScoresGaussian))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Gaussian/Bernoulli w/ SMOTE (Cross-Validated 7-Fold):\n",
      "Recall mean: 0.6409513107006365\n",
      "Accuracy mean: 0.7713818624016494\n",
      "F1 Score mean: 0.2139777524537915\n",
      "\n",
      "Bernoulli w/ SMOTE (Cross-Validated 7-Fold):\n",
      "Recall mean: 0.2615820711496333\n",
      "Accuracy mean: 0.7946714127333101\n",
      "F1 Score mean: 0.11314140818365222\n",
      "\n",
      "Gaussian w/ SMOTE (Cross-Validated 7-Fold):\n",
      "Recall mean: 0.834993298930181\n",
      "Accuracy mean: 0.7001355635551475\n",
      "F1 Score mean: 0.21291448300732174\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes w/ SMOTE Cross Validated (7-Fold)\n",
    "\n",
    "kf = KFold(n_splits = 7)\n",
    "\n",
    "recallScoresCombined = []\n",
    "accuracyScoresCombined = []\n",
    "f1ScoresCombined = []\n",
    "\n",
    "recallScoresGaussian = []\n",
    "accuracyScoresGaussian = []\n",
    "f1ScoresGaussian = []\n",
    "\n",
    "recallScoresBernoulli = []\n",
    "accuracyScoresBernoulli = []\n",
    "f1ScoresBernoulli = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(data), 1):\n",
    "    X_train = data.iloc[train_index]\n",
    "    y_train = target.iloc[train_index]\n",
    "    X_test = data.iloc[test_index]\n",
    "    y_test = target.iloc[test_index]\n",
    "\n",
    "    sm = SMOTE()\n",
    "    X_train_oversampled, y_train_oversampled = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "    bernoulliSet = X_train_oversampled.drop(columns=[\"avg_glucose_level\", \"age\"])\n",
    "    gaussianSet = X_train_oversampled[[\"avg_glucose_level\", \"age\"]]\n",
    "\n",
    "    bernoulliClassifier = BernoulliNB()\n",
    "    gaussianClassifier = GaussianNB()\n",
    "\n",
    "    bernoulliTest = X_test.drop(columns=[\"avg_glucose_level\", \"age\"])\n",
    "    gaussianTest = X_test[[\"avg_glucose_level\", \"age\"]]\n",
    "\n",
    "    bernoulliProb = bernoulliClassifier.fit(bernoulliSet, y_train_oversampled).predict_proba(bernoulliTest)\n",
    "    gaussianProb = gaussianClassifier.fit(gaussianSet, y_train_oversampled).predict_proba(gaussianTest)\n",
    "    prediction = (np.argmax(bernoulliProb*gaussianProb, axis = 1))\n",
    "\n",
    "    recallScoresCombined.append(recall_score(y_test, prediction))\n",
    "    accuracyScoresCombined.append(accuracy_score(y_test, prediction))\n",
    "    f1ScoresCombined.append(f1_score(y_test, prediction))\n",
    "\n",
    "    prediction = bernoulliClassifier.fit(bernoulliSet, y_train_oversampled).predict(bernoulliTest)\n",
    "    \n",
    "    recallScoresBernoulli.append(recall_score(y_test, prediction))\n",
    "    accuracyScoresBernoulli.append(accuracy_score(y_test, prediction))\n",
    "    f1ScoresBernoulli.append(f1_score(y_test, prediction))\n",
    "    \n",
    "    prediction = gaussianClassifier.fit(gaussianSet, y_train_oversampled).predict(gaussianTest)\n",
    "\n",
    "    recallScoresGaussian.append(recall_score(y_test, prediction))\n",
    "    accuracyScoresGaussian.append(accuracy_score(y_test, prediction))\n",
    "    f1ScoresGaussian.append(f1_score(y_test, prediction))\n",
    "\n",
    "print(\"Combined Gaussian/Bernoulli w/ SMOTE (Cross-Validated 7-Fold):\")\n",
    "print(\"Recall mean:\", np.mean(recallScoresCombined))\n",
    "print(\"Accuracy mean:\", np.mean(accuracyScoresCombined))\n",
    "print(\"F1 Score mean:\", np.mean(f1ScoresCombined))\n",
    "print()\n",
    "\n",
    "print(\"Bernoulli w/ SMOTE (Cross-Validated 7-Fold):\")\n",
    "print(\"Recall mean:\", np.mean(recallScoresBernoulli))\n",
    "print(\"Accuracy mean:\", np.mean(accuracyScoresBernoulli))\n",
    "print(\"F1 Score mean:\", np.mean(f1ScoresBernoulli))\n",
    "print()\n",
    "\n",
    "print(\"Gaussian w/ SMOTE (Cross-Validated 7-Fold):\")\n",
    "print(\"Recall mean:\", np.mean(recallScoresGaussian))\n",
    "print(\"Accuracy mean:\", np.mean(accuracyScoresGaussian))\n",
    "print(\"F1 Score mean:\", np.mean(f1ScoresGaussian))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier w/o SMOTE:\n",
      "Recall mean: 0.008\n",
      "Accuracy mean: 0.9451945542818041\n",
      "F1 Score mean: 0.013793103448275865\n",
      "\n",
      "KNN Classifier w/ SMOTE:\n",
      "Recall mean: 0.5460408163265306\n",
      "Accuracy mean: 0.7860627411443828\n",
      "F1 Score mean: 0.19855744247162455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#K-Nearest Neighbors (No Parameter Tuning/Cross Validated)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "print(\"KNN Classifier w/o SMOTE:\")\n",
    "print(\"Recall mean:\", np.mean(cross_validate(knn, data, target, scoring=\"recall\")[\"test_score\"]))\n",
    "print(\"Accuracy mean:\", np.mean(cross_validate(knn, data, target, scoring=\"accuracy\")[\"test_score\"]))\n",
    "print(\"F1 Score mean:\", np.mean(cross_validate(knn, data, target, scoring=\"f1\")[\"test_score\"]))\n",
    "print()\n",
    "\n",
    "model = Pipeline([('sampling', SMOTE()),('classification', KNeighborsClassifier())])\n",
    "\n",
    "print(\"KNN Classifier w/ SMOTE:\")\n",
    "print(\"Recall mean:\", np.mean(cross_validate(model, data, target, scoring=\"recall\")[\"test_score\"]))\n",
    "print(\"Accuracy mean:\", np.mean(cross_validate(model, data, target, scoring=\"accuracy\")[\"test_score\"]))\n",
    "print(\"F1 Score mean:\", np.mean(cross_validate(model, data, target, scoring=\"f1\")[\"test_score\"]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier w/o SMOTE and parameter tuning via GridSearch:\n",
      "Recall mean: 0.14065306122448978\n",
      "Accuracy mean: 0.9168130703370128\n",
      "F1 Score mean: 0.13964015239726799\n",
      "\n",
      "KNN Classifier w/ SMOTE and parameter tuning via GridSearch:\n",
      "Recall mean: 0.614530612244898\n",
      "Accuracy mean: 0.7764715916823037\n",
      "F1 Score mean: 0.21169656545130197\n"
     ]
    }
   ],
   "source": [
    "#KNN Neighbors Classifier (parameter tuning through gridSearch)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "parameters = {'n_neighbors':[2,3,4,5,6,7,8,9,10], \"weights\":[\"uniform\", \"distance\"]}\n",
    "gridSearch = GridSearchCV(knn, parameters, scoring=\"f1\")\n",
    "gridSearch.fit(data, target)\n",
    "\n",
    "print(\"KNN Classifier w/o SMOTE and parameter tuning via GridSearch:\")\n",
    "print(\"Recall mean:\", np.mean(cross_validate(gridSearch.best_estimator_, data, target, scoring=\"recall\")[\"test_score\"]))\n",
    "print(\"Accuracy mean:\", np.mean(cross_validate(gridSearch.best_estimator_, data, target, scoring=\"accuracy\")[\"test_score\"]))\n",
    "print(\"F1 Score mean:\", np.mean(cross_validate(gridSearch.best_estimator_, data, target, scoring=\"f1\")[\"test_score\"]))\n",
    "print()\n",
    "\n",
    "model = Pipeline([('sampling', SMOTE()),('classification', KNeighborsClassifier())])\n",
    "\n",
    "parameters = {'classification__n_neighbors':[2,3,4,5,6,7,8,9,10], \"classification__weights\":[\"uniform\", \"distance\"]}\n",
    "gridSearch = GridSearchCV(model, parameters, scoring=\"f1\")\n",
    "gridSearch.fit(data,target)\n",
    "\n",
    "print(\"KNN Classifier w/ SMOTE and parameter tuning via GridSearch:\")\n",
    "print(\"Recall mean:\", np.mean(cross_validate(gridSearch.best_estimator_, data, target, scoring=\"recall\")[\"test_score\"]))\n",
    "print(\"Accuracy mean:\", np.mean(cross_validate(gridSearch.best_estimator_, data, target, scoring=\"accuracy\")[\"test_score\"]))\n",
    "print(\"F1 Score mean:\", np.mean(cross_validate(gridSearch.best_estimator_, data, target, scoring=\"f1\")[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier w/o SMOTE and parameter tuning via GridSearch with Standard Scalar Preprocessing:\n",
      "Recall mean: 0.10457142857142858\n",
      "Accuracy mean: 0.918965712215682\n",
      "F1 Score mean: 0.11061164467196574\n",
      "\n",
      "KNN Classifier w/ SMOTE and parameter tuning via GridSearch with Standard Scalar Preprocessing:\n",
      "Recall mean: 0.14057142857142857\n",
      "Accuracy mean: 0.9342350751632547\n",
      "F1 Score mean: 0.1581175483766787\n"
     ]
    }
   ],
   "source": [
    "#KNN Neighbors Classifier (parameter tuning through gridSearch/Standard Scalar Preprocessing)\n",
    "\n",
    "model = Pipeline([('scale', StandardScaler()),('classification', KNeighborsClassifier())])\n",
    "\n",
    "parameters = {'classification__n_neighbors':[2,3,4,5,6,7,8,9,10], \"classification__weights\":[\"uniform\", \"distance\"]}\n",
    "gridSearch = GridSearchCV(model, parameters, scoring=\"f1\")\n",
    "gridSearch.fit(data, target)\n",
    "\n",
    "print(\"KNN Classifier w/o SMOTE and parameter tuning via GridSearch with Standard Scalar Preprocessing:\")\n",
    "print(\"Recall mean:\", np.mean(cross_validate(gridSearch.best_estimator_, data, target, scoring=\"recall\")[\"test_score\"]))\n",
    "print(\"Accuracy mean:\", np.mean(cross_validate(gridSearch.best_estimator_, data, target, scoring=\"accuracy\")[\"test_score\"]))\n",
    "print(\"F1 Score mean:\", np.mean(cross_validate(gridSearch.best_estimator_, data, target, scoring=\"f1\")[\"test_score\"]))\n",
    "print()\n",
    "\n",
    "model = Pipeline([('sampling', SMOTE()),('scale', StandardScaler()),('classification', KNeighborsClassifier())])\n",
    "\n",
    "parameters = {'classification__n_neighbors':[2,3,4,5,6,7,8,9,10], \"classification__weights\":[\"uniform\", \"distance\"]}\n",
    "gridSearch = GridSearchCV(model, parameters, scoring=\"f1\")\n",
    "gridSearch.fit(data,target)\n",
    "\n",
    "print(\"KNN Classifier w/ SMOTE and parameter tuning via GridSearch with Standard Scalar Preprocessing:\")\n",
    "print(\"Recall mean:\", np.mean(cross_validate(gridSearch.best_estimator_, data, target, scoring=\"recall\")[\"test_score\"]))\n",
    "print(\"Accuracy mean:\", np.mean(cross_validate(gridSearch.best_estimator_, data, target, scoring=\"accuracy\")[\"test_score\"]))\n",
    "print(\"F1 Score mean:\", np.mean(cross_validate(gridSearch.best_estimator_, data, target, scoring=\"f1\")[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier w/o SMOTE:\n",
      "Recall mean: 0.044163265306122454\n",
      "Accuracy mean: 0.9483270114292613\n",
      "F1 Score mean: 0.07637540666394216\n",
      "\n",
      "Random Forest Classifier w/ SMOTE:\n",
      "Recall mean: 0.048\n",
      "Accuracy mean: 0.9397143355483955\n",
      "F1 Score mean: 0.08307272908376977\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier (parameter tuning through gridSearch/Standard Scalar Preprocessing)\n",
    "\n",
    "model = Pipeline([('classification', RandomForestClassifier())])\n",
    "\n",
    "print(\"Random Forest Classifier w/o SMOTE:\")\n",
    "print(\"Recall mean:\", np.mean(cross_validate(model, data, target, scoring=\"recall\")[\"test_score\"]))\n",
    "print(\"Accuracy mean:\", np.mean(cross_validate(model, data, target, scoring=\"accuracy\")[\"test_score\"]))\n",
    "print(\"F1 Score mean:\", np.mean(cross_validate(model, data, target, scoring=\"f1\")[\"test_score\"]))\n",
    "print()\n",
    "\n",
    "model = Pipeline([('sampling', SMOTE()),('classification', RandomForestClassifier())])\n",
    "\n",
    "\n",
    "print(\"Random Forest Classifier w/ SMOTE:\")\n",
    "print(\"Recall mean:\", np.mean(cross_validate(model, data, target, scoring=\"recall\")[\"test_score\"]))\n",
    "print(\"Accuracy mean:\", np.mean(cross_validate(model, data, target, scoring=\"accuracy\")[\"test_score\"]))\n",
    "print(\"F1 Score mean:\", np.mean(cross_validate(model, data, target, scoring=\"f1\")[\"test_score\"]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier w/o SMOTE and parameter tuning via GridSearch:\n",
      "Recall mean: 0.036244897959183675\n",
      "Accuracy mean: 0.9516542049446939\n",
      "F1 Score mean: 0.07464837049742709\n",
      "\n",
      "Random Forest Classifier w/o SMOTE and parameter tuning via GridSearch with Standard Scalar Preprocessing:\n",
      "Recall mean: 0.036244897959183675\n",
      "Accuracy mean: 0.9512631988515154\n",
      "F1 Score mean: 0.061393323657474595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier (parameter tuning through gridSearch/Standard Scalar Preprocessing)\n",
    "\n",
    "model = Pipeline([('classification', RandomForestClassifier())])\n",
    "\n",
    "parameters = {'classification__n_estimators':[200], \"classification__max_depth\": [2,3,4,5], \"classification__max_features\": [\"auto\", \"log2\", None]}\n",
    "gridSearch = GridSearchCV(model, parameters, scoring=\"f1\")\n",
    "gridSearch.fit(data, target)\n",
    "\n",
    "print(\"Random Forest Classifier w/o SMOTE and parameter tuning via GridSearch:\")\n",
    "print(\"Recall mean:\", np.mean(cross_validate(gridSearch.best_estimator_, data, target, scoring=\"recall\")[\"test_score\"]))\n",
    "print(\"Accuracy mean:\", np.mean(cross_validate(gridSearch.best_estimator_, data, target, scoring=\"accuracy\")[\"test_score\"]))\n",
    "print(\"F1 Score mean:\", np.mean(cross_validate(gridSearch.best_estimator_, data, target, scoring=\"f1\")[\"test_score\"]))\n",
    "print()\n",
    "\n",
    "model = Pipeline([('scale', StandardScaler()),('classification', RandomForestClassifier())])\n",
    "\n",
    "parameters = {'classification__n_estimators':[200], \"classification__max_depth\": [2,3,4,5], \"classification__max_features\": [\"auto\", \"log2\", None]}\n",
    "gridSearch = GridSearchCV(model, parameters, scoring=\"f1\")\n",
    "gridSearch.fit(data, target)\n",
    "\n",
    "print(\"Random Forest Classifier w/o SMOTE and parameter tuning via GridSearch with Standard Scalar Preprocessing:\")\n",
    "print(\"Recall mean:\", np.mean(cross_validate(gridSearch.best_estimator_, data, target, scoring=\"recall\")[\"test_score\"]))\n",
    "print(\"Accuracy mean:\", np.mean(cross_validate(gridSearch.best_estimator_, data, target, scoring=\"accuracy\")[\"test_score\"]))\n",
    "print(\"F1 Score mean:\", np.mean(cross_validate(gridSearch.best_estimator_, data, target, scoring=\"f1\")[\"test_score\"]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier w/ SMOTE and parameter tuning via GridSearch:\n",
      "Recall mean: 0.4619591836734694\n",
      "Accuracy mean: 0.8434129848523473\n",
      "F1 Score mean: 0.22900447385735462\n",
      "\n",
      "Random Forest Classifier w/ SMOTE and parameter tuning via GridSearch with Standard Scalar Preprocessing:\n",
      "Recall mean: 0.49020408163265305\n",
      "Accuracy mean: 0.8351913150646597\n",
      "F1 Score mean: 0.22730059569403274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier (parameter tuning through gridSearch/Standard Scalar Preprocessing)\n",
    "\n",
    "model = Pipeline([('sampling', SMOTE()),('classification', RandomForestClassifier())])\n",
    "\n",
    "parameters = {'classification__n_estimators':[200], \"classification__max_depth\": [2,3,4,5], \"classification__max_features\": [\"auto\", \"log2\", None]}\n",
    "gridSearch = GridSearchCV(model, parameters, scoring=\"f1\")\n",
    "gridSearch.fit(data, target)\n",
    "\n",
    "print(\"Random Forest Classifier w/ SMOTE and parameter tuning via GridSearch:\")\n",
    "print(\"Recall mean:\", np.mean(cross_validate(gridSearch.best_estimator_, data, target, scoring=\"recall\")[\"test_score\"]))\n",
    "print(\"Accuracy mean:\", np.mean(cross_validate(gridSearch.best_estimator_, data, target, scoring=\"accuracy\")[\"test_score\"]))\n",
    "print(\"F1 Score mean:\", np.mean(cross_validate(gridSearch.best_estimator_, data, target, scoring=\"f1\")[\"test_score\"]))\n",
    "print()\n",
    "\n",
    "model = Pipeline([('sampling', SMOTE()),('scale', StandardScaler()),('classification', RandomForestClassifier())])\n",
    "\n",
    "parameters = {'classification__n_estimators':[200], \"classification__max_depth\": [2,3,4,5], \"classification__max_features\": [\"auto\", \"log2\", None]}\n",
    "gridSearch = GridSearchCV(model, parameters, scoring=\"f1\")\n",
    "gridSearch.fit(data, target)\n",
    "\n",
    "print(\"Random Forest Classifier w/ SMOTE and parameter tuning via GridSearch with Standard Scalar Preprocessing:\")\n",
    "print(\"Recall mean:\", np.mean(cross_validate(gridSearch.best_estimator_, data, target, scoring=\"recall\")[\"test_score\"]))\n",
    "print(\"Accuracy mean:\", np.mean(cross_validate(gridSearch.best_estimator_, data, target, scoring=\"accuracy\")[\"test_score\"]))\n",
    "print(\"F1 Score mean:\", np.mean(cross_validate(gridSearch.best_estimator_, data, target, scoring=\"f1\")[\"test_score\"]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = data_cleaning(\"healthcare-dataset-stroke-data.csv\", onehotencode=True, categorical_col=['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status'], onehotencode_column=['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifier w/o SMOTE:\n",
      "Recall mean: 0.016\n",
      "Accuracy mean: 0.9504796533079307\n",
      "F1 Score mean: 0.03019405472235661\n",
      "\n",
      "Logistic Regression Classifier w/ SMOTE:\n",
      "Recall mean: 0.04408163265306122\n",
      "Accuracy mean: 0.9469556150583347\n",
      "F1 Score mean: 0.09046198510674353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier (parameter tuning through gridSearch/Standard Scalar Preprocessing)\n",
    "\n",
    "model = Pipeline([('classification', LogisticRegression(solver=\"newton-cg\"))])\n",
    "\n",
    "print(\"Logistic Regression Classifier w/o SMOTE:\")\n",
    "print(\"Recall mean:\", np.mean(cross_validate(model, data, target, scoring=\"recall\")[\"test_score\"]))\n",
    "print(\"Accuracy mean:\", np.mean(cross_validate(model, data, target, scoring=\"accuracy\")[\"test_score\"]))\n",
    "print(\"F1 Score mean:\", np.mean(cross_validate(model, data, target, scoring=\"f1\")[\"test_score\"]))\n",
    "print()\n",
    "\n",
    "model = Pipeline([('sampling', SMOTE()),('classification', LogisticRegression(solver=\"newton-cg\"))])\n",
    "\n",
    "\n",
    "print(\"Logistic Regression Classifier w/ SMOTE:\")\n",
    "print(\"Recall mean:\", np.mean(cross_validate(model, data, target, scoring=\"recall\")[\"test_score\"]))\n",
    "print(\"Accuracy mean:\", np.mean(cross_validate(model, data, target, scoring=\"accuracy\")[\"test_score\"]))\n",
    "print(\"F1 Score mean:\", np.mean(cross_validate(model, data, target, scoring=\"f1\")[\"test_score\"]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cayma\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\cayma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Combination for f1:\n",
      "Logistic Regression Classifier w/o SMOTE Standard Scalar Preprocessing:\n",
      "Recall mean: 0.004\n",
      "Accuracy mean: 0.9499021526418787\n",
      "F1 Score mean: 0.007692307692307693\n",
      "\n",
      "Logistic Regression Classifier w/ SMOTE and Standard Scalar Preprocessing:\n",
      "Recall mean: 0.42122448979591837\n",
      "Accuracy mean: 0.8733855185909979\n",
      "F1 Score mean: 0.24344828508140628\n",
      "\n",
      "['gender', 'ever_married', 'work_type', 'Residence_type']\n",
      "\n",
      "Best Feature Combination for recall:\n",
      "Logistic Regression Classifier w/o SMOTE Standard Scalar Preprocessing:\n",
      "Recall mean: 0.008\n",
      "Accuracy mean: 0.9504892367906066\n",
      "F1 Score mean: 0.015250544662309368\n",
      "\n",
      "Logistic Regression Classifier w/ SMOTE and Standard Scalar Preprocessing:\n",
      "Recall mean: 0.614204081632653\n",
      "Accuracy mean: 0.7724070450097847\n",
      "F1 Score mean: 0.20786197872210194\n",
      "\n",
      "['gender', 'smoking_status', 'work_type', 'Residence_type']\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier (parameter tuning through gridSearch/Standard Scalar Preprocessing)\n",
    "\n",
    "catcol = ['gender', \"smoking_status\", 'ever_married','work_type', 'Residence_type']\n",
    "maxf1 = 0\n",
    "maxRecall = 0\n",
    "for r in range(0,5):\n",
    "    for combo in itertools.combinations(catcol, r):\n",
    "        current = [x for x in catcol if x not in combo]\n",
    "        combo = list(combo)\n",
    "        data, target = data_cleaning(\"healthcare-dataset-stroke-data.csv\", onehotencode=True, categorical_col=current, onehotencode_column=current, drop_column=combo)\n",
    "\n",
    "        model = Pipeline([('sampling', SMOTE()),('classification', LogisticRegression(solver=\"newton-cg\"))])\n",
    "\n",
    "        f1 = np.mean(cross_validate(model, data, target, scoring=\"f1\")[\"test_score\"])\n",
    "        if maxf1 < f1:\n",
    "            maxf1 = f1\n",
    "            bestCurrentf1 = current\n",
    "            bestCombof1 = combo\n",
    "\n",
    "        recall = np.mean(cross_validate(model, data, target, scoring=\"recall\")[\"test_score\"])\n",
    "        if maxRecall < recall:\n",
    "            maxRecall = recall\n",
    "            bestCurrentRecall = current\n",
    "            bestComboRecall = combo\n",
    "\n",
    "print(\"Best Feature Combination for f1:\")\n",
    "data, target = data_cleaning(\"healthcare-dataset-stroke-data.csv\", onehotencode=True, categorical_col=bestCurrentf1, onehotencode_column=bestCurrentf1, drop_column=bestCombof1)\n",
    "\n",
    "model = Pipeline([('classification', LogisticRegression(solver=\"newton-cg\"))])\n",
    "\n",
    "print(\"Logistic Regression Classifier w/o SMOTE Standard Scalar Preprocessing:\")\n",
    "print(\"Recall mean:\", np.mean(cross_validate(model, data, target, scoring=\"recall\")[\"test_score\"]))\n",
    "print(\"Accuracy mean:\", np.mean(cross_validate(model, data, target, scoring=\"accuracy\")[\"test_score\"]))\n",
    "print(\"F1 Score mean:\", np.mean(cross_validate(model, data, target, scoring=\"f1\")[\"test_score\"]))\n",
    "print()\n",
    "\n",
    "model = Pipeline([('sampling', SMOTE()),('classification', LogisticRegression(solver=\"newton-cg\"))])\n",
    "\n",
    "\n",
    "print(\"Logistic Regression Classifier w/ SMOTE and Standard Scalar Preprocessing:\")\n",
    "print(\"Recall mean:\", np.mean(cross_validate(model, data, target, scoring=\"recall\")[\"test_score\"]))\n",
    "print(\"Accuracy mean:\", np.mean(cross_validate(model, data, target, scoring=\"accuracy\")[\"test_score\"]))\n",
    "print(\"F1 Score mean:\", np.mean(cross_validate(model, data, target, scoring=\"f1\")[\"test_score\"]))\n",
    "print()\n",
    "\n",
    "print(bestCombof1)\n",
    "\n",
    "print()\n",
    "print(\"Best Feature Combination for recall:\")\n",
    "data, target = data_cleaning(\"healthcare-dataset-stroke-data.csv\", onehotencode=True, categorical_col=bestCurrentRecall, onehotencode_column=bestCurrentRecall, drop_column=bestComboRecall)\n",
    "\n",
    "model = Pipeline([('classification', LogisticRegression(solver=\"newton-cg\"))])\n",
    "\n",
    "print(\"Logistic Regression Classifier w/o SMOTE Standard Scalar Preprocessing:\")\n",
    "print(\"Recall mean:\", np.mean(cross_validate(model, data, target, scoring=\"recall\")[\"test_score\"]))\n",
    "print(\"Accuracy mean:\", np.mean(cross_validate(model, data, target, scoring=\"accuracy\")[\"test_score\"]))\n",
    "print(\"F1 Score mean:\", np.mean(cross_validate(model, data, target, scoring=\"f1\")[\"test_score\"]))\n",
    "print()\n",
    "\n",
    "model = Pipeline([('sampling', SMOTE()),('classification', LogisticRegression(solver=\"newton-cg\"))])\n",
    "\n",
    "\n",
    "print(\"Logistic Regression Classifier w/ SMOTE and Standard Scalar Preprocessing:\")\n",
    "print(\"Recall mean:\", np.mean(cross_validate(model, data, target, scoring=\"recall\")[\"test_score\"]))\n",
    "print(\"Accuracy mean:\", np.mean(cross_validate(model, data, target, scoring=\"accuracy\")[\"test_score\"]))\n",
    "print(\"F1 Score mean:\", np.mean(cross_validate(model, data, target, scoring=\"f1\")[\"test_score\"]))\n",
    "print()\n",
    "\n",
    "print(bestComboRecall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of Learning Algorithms:\n",
    "\n",
    "We tried a variety of classifiers in an attempt to create a model that could accurately (and more importantly, with high recall) predict stroke occurances using the health data provided. One important characteristic of our dataset is that it is heavily imbalanced. The null hypothesis (predicting no stroke occurances across the board) results in a model with about 95% accuracy. Thus, it is extremely important that we focus on the recall of the model and the f1 scores, which represent a sort of balance between the accuracy and the recall scores. Experimentally, raising a model's recall by changing model parameters or using SMOTE to oversample the training data results in a lowering of the accuracy so there is a practical trade-off between the two scores. However, the null hypothesis model is quite obviously useless so it's a trade-off we need to make in order to get any kind of applicable model.\n",
    "\n",
    "Treating the natural imbalance in the data is of utmost importance. The Syntethic Minority Oversampling Technique (SMOTE) is used to take the minority class (in this case, stroke occurances) and creating fake examples that are close to the other stroke occurances in the feature space. In all of our attempted models, oversampling with SMOTE greatly improves both recall and the f1 score from the corresponding baseline model that was trained only on the provided data. Regardless of the classifier type, the models were effectively useless without oversampling. Thus, the most important step in model creation for our dataset is using SMOTE in our pipeline. We also played around with other preprocessing steps such as using sklearn's StandardScaler, but this reduces the scoring of our models across the board.\n",
    "\n",
    "Only two of the provided features are continuous/numerical, so Gaussian Discriminant Analysis was not an appropriate tool to use due to the fact that it assumes that the features are normally distributed. Instead, we turned to Naive Bayes as a potential model because it can handle both Gaussian and Binary distributed features. Due to the fact that Naive Bayes assumes independence between the features, we can split the dataset into Gaussian and Bernoulli features and get final probabilities at the end by multiplying the probabilities of the two separate models together. For each of the sets, we can train a Naive Bayes model of the corresponding type on just the appropriate features. Then, rather than using the predict method to get labels, we grab the probabilities for each class. Multiplying these newly calculated probabilities together from both the Gaussian and Bernoulli models, we get a \"combined\" probability that accounts for all of the features in the data. Then, assigning class labels is as easy as choosing the argmax of the resultant probabilities for each input. In addition to being theoretically sound (by the assumed independence of features), we experimentally see that the combined model improves on the f1 scores of both subset models. Using this combined model (w/ SMOTE), we end up with a recall of $0.65$, an accuracy of $0.79$, and an f1 of around $0.24$. Unfortunately, there aren't a whole lot of model parameters that can be changed for the Naive Bayes model. The only possiblity being \"var_smoothing\" which is just used for calculation stability on GaussianNB and \"alpha\" a smoothing parameter for BernoulliNB. Thus, the best we can do with Naive Bayes is an f1 score of $0.24$. \n",
    "\n",
    "Another option we explored as a way to predict stroke occurances was a K-Nearest Neighbors Classifier. Without SMOTE or any fine tuning of parameters, the model is useless with a recall score around $.01$ and an f1 score of about $0.02$. Oversampling immediately yields much better results with a recall score of about $0.51$, an accuracy of $0.79$, and an f1 score of around $0.19$ which is actually already decent compared to our scores on the Naive Bayes. Unfortunately, the tuning of model parameters using GridSearch doesn't improve the SMOTE model significantly. It provides a slight jump up to a recall of $.59$, a slight accuracy decrease to $.78$, and a slight jump up to a f1 score of about $.21$. Thus, even with all the improvements we could make with our KNN classifier, it underperforms when compared to the combined Naive Bayes model we talked about previously."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b4a22ef55f1677bb95c5c32c0ec0f93ada970bc391369c7e693145400d5c0908"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
